{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_companies = ['TCS', 'HUL', 'INFY', 'SAIL', 'MRF', 'SRF', 'PVR.NS', 'IDBI.NS', 'RITES.NS']\n",
    "\n",
    "for company in li_companies:\n",
    "    \n",
    "    print(\"Company : \", company)\n",
    "\n",
    "    import yfinance as yf\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    data = yf.download(company, start=\"2015-01-01\")\n",
    "    data = data.dropna()\n",
    "\n",
    "    df1=data.reset_index()['Close']\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(df1)\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    df1 = scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
    "\n",
    "    ##splitting dataset into train and test split\n",
    "    training_size = int(len(df1)*0.65)\n",
    "    test_size = len(df1)-training_size\n",
    "    train_data,test_data = df1[0:training_size,:],df1[training_size:len(df1),:1]\n",
    "\n",
    "    # convert an array of values into a dataset matrix\n",
    "    def create_dataset(dataset, time_step):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-time_step-1):\n",
    "            a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + time_step, 0])\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    time_step = 100\n",
    "    X_train, Y_train = create_dataset(train_data, time_step)\n",
    "    X_test, Y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] , 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] , 1)\n",
    "\n",
    "    Y_train = Y_train.reshape(Y_train.shape[0], 1)\n",
    "    Y_test = Y_test.reshape(Y_test.shape[0], 1)\n",
    "\n",
    "    ### Create the Stacked LSTM model\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import LSTM, GRU\n",
    "    from keras import Model\n",
    "\n",
    "    model_lstm=Sequential()\n",
    "    model_lstm.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
    "    model_lstm.add(LSTM(50,return_sequences=True))\n",
    "    model_lstm.add(LSTM(50))\n",
    "    model_lstm.add(Dense(1))\n",
    "    model_lstm.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "    model_lstm.summary()\n",
    "\n",
    "    model_lstm.fit(X_train, Y_train, validation_data = (X_test,Y_test), epochs=10, batch_size=64, verbose=1)\n",
    "    model_lstm.save('Stock_pred_model_lstm.h5')\n",
    "    \n",
    "    ### Lets Do the prediction and check performance metrics\n",
    "    train_predict=model_lstm.predict(X_train)\n",
    "    test_predict=model_lstm.predict(X_test)\n",
    "\n",
    "    ##Transformback to original form\n",
    "    train_predict=scaler.inverse_transform(train_predict)\n",
    "    test_predict=scaler.inverse_transform(test_predict)\n",
    "\n",
    "    import math\n",
    "    import numpy\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "\n",
    "    print(\"Train Error LSTM : \", math.sqrt(mean_squared_error(Y_train,train_predict)))\n",
    "    print(\"Test Error LSTM : \", math.sqrt(mean_squared_error(Y_test,test_predict)))\n",
    "\n",
    "    ### Plotting \n",
    "    look_back=100\n",
    "    trainPredictPlot = numpy.empty_like(df1)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "    testPredictPlot = numpy.empty_like(df1)\n",
    "    testPredictPlot[:, :] = numpy.nan\n",
    "    testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
    "\n",
    "    plt.plot(scaler.inverse_transform(df1))\n",
    "    plt.plot(trainPredictPlot)\n",
    "    plt.plot(testPredictPlot)\n",
    "\n",
    "    x_input = test_data[X_test.shape[0]:].reshape(1,-1)\n",
    "    temp_input = list(x_input)\n",
    "    temp_input = temp_input[0].tolist()\n",
    "\n",
    "    # demonstrate prediction for next no of defined days\n",
    "    from numpy import array\n",
    "\n",
    "    lst_output = []\n",
    "    n_steps = 100\n",
    "    i = 0\n",
    "    no_of_days = 30\n",
    "\n",
    "    while(i < no_of_days):\n",
    "\n",
    "        if(len(temp_input)>100):\n",
    "            x_input = np.array(temp_input[1:])\n",
    "            x_input = x_input.reshape(1,-1)\n",
    "            x_input = x_input.reshape((1, n_steps, 1))\n",
    "            yhat = model_lstm.predict(x_input, verbose=0)\n",
    "            temp_input.extend(yhat[0].tolist())\n",
    "            temp_input=temp_input[1:]\n",
    "            lst_output.extend(yhat.tolist())\n",
    "            i=i+1\n",
    "\n",
    "        else:\n",
    "            x_input = x_input.reshape((1, n_steps,1))\n",
    "            yhat = model_lstm.predict(x_input, verbose=0)\n",
    "            temp_input.extend(yhat[0].tolist())\n",
    "            lst_output.extend(yhat.tolist())\n",
    "            i=i+1\n",
    "\n",
    "    final_out = scaler.inverse_transform(lst_output)\n",
    "    d = {'Output' : list(final_out)}\n",
    "    final_df = pd.DataFrame(d) \n",
    "    \n",
    "    import os \n",
    "    if os.path.isdir(company):\n",
    "        final_df.to_csv(company + '/' + company + '_lstm.csv')\n",
    "        plt.savefig(company + '/' + company + '_lstm.jpg')\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        os.mkdir(company)\n",
    "        final_df.to_csv(company + '/' + company + '_lstm.csv')\n",
    "        plt.savefig(company + '/' + company + '_lstm.jpg')\n",
    "        plt.show()\n",
    "        \n",
    "    print(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_companies = ['TCS', 'HUL', 'INFY', 'SAIL', 'MRF', 'SRF', 'PVR.NS', 'IDBI.NS', 'RITES.NS']\n",
    "    \n",
    "final_li = []\n",
    "for company in li_companies:\n",
    "    \n",
    "    print(\"Company : \", company)\n",
    "\n",
    "    import yfinance as yf\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    data = yf.download(company, start=\"2015-01-01\")\n",
    "    data = data.dropna()\n",
    "\n",
    "    df1=data.reset_index()['Close']\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(df1)\n",
    "\n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(0,1))\n",
    "    df1 = scaler.fit_transform(np.array(df1).reshape(-1,1))\n",
    "\n",
    "    ##splitting dataset into train and test split\n",
    "    training_size = int(len(df1)*0.65)\n",
    "    test_size = len(df1)-training_size\n",
    "    train_data,test_data = df1[0:training_size,:],df1[training_size:len(df1),:1]\n",
    "\n",
    "    # convert an array of values into a dataset matrix\n",
    "    def create_dataset(dataset, time_step):\n",
    "        dataX, dataY = [], []\n",
    "        for i in range(len(dataset)-time_step-1):\n",
    "            a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "            dataX.append(a)\n",
    "            dataY.append(dataset[i + time_step, 0])\n",
    "        return np.array(dataX), np.array(dataY)\n",
    "\n",
    "    time_step = 100\n",
    "    X_train, Y_train = create_dataset(train_data, time_step)\n",
    "    X_test, Y_test = create_dataset(test_data, time_step)\n",
    "\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1] , 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1] , 1)\n",
    "\n",
    "    Y_train = Y_train.reshape(Y_train.shape[0], 1)\n",
    "    Y_test = Y_test.reshape(Y_test.shape[0], 1)\n",
    "    \n",
    "    ### Create the Stacked LSTM model\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense\n",
    "    from keras.layers import LSTM, GRU\n",
    "    from keras import Model\n",
    "\n",
    "    model_gru=Sequential()\n",
    "    model_gru.add(GRU(50,return_sequences=True,input_shape=(100,1)))\n",
    "    model_gru.add(GRU(50,return_sequences=True))\n",
    "    model_gru.add(GRU(50))\n",
    "    model_gru.add(Dense(1))\n",
    "    model_gru.compile(loss='mean_squared_error',optimizer='adam')\n",
    "\n",
    "    model_gru.summary()\n",
    "\n",
    "    model_gru.fit(X_train, Y_train, validation_data = (X_test,Y_test), epochs=10, batch_size=64, verbose=1)\n",
    "    model_gru.save('Stock_pred_model_gru.h5')\n",
    "\n",
    "    ### Lets Do the prediction and check performance metrics\n",
    "    train_predict=model_gru.predict(X_train)\n",
    "    test_predict=model_gru.predict(X_test)\n",
    "\n",
    "    ##Transformback to original form\n",
    "    train_predict=scaler.inverse_transform(train_predict)\n",
    "    test_predict=scaler.inverse_transform(test_predict)\n",
    "\n",
    "    ### Calculate RMSE performance metrics\n",
    "    import math\n",
    "    import numpy\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    print(\"Train Error : \", math.sqrt(mean_squared_error(Y_train,train_predict)))\n",
    "    print(\"Test Error  : \", math.sqrt(mean_squared_error(Y_test,test_predict)))\n",
    "\n",
    "    ### Plotting \n",
    "    look_back=100\n",
    "    trainPredictPlot = numpy.empty_like(df1)\n",
    "    trainPredictPlot[:, :] = np.nan\n",
    "    trainPredictPlot[look_back:len(train_predict)+look_back, :] = train_predict\n",
    "    testPredictPlot = numpy.empty_like(df1)\n",
    "    testPredictPlot[:, :] = numpy.nan\n",
    "    testPredictPlot[len(train_predict)+(look_back*2)+1:len(df1)-1, :] = test_predict\n",
    "\n",
    "    plt.plot(scaler.inverse_transform(df1))\n",
    "    plt.plot(trainPredictPlot)\n",
    "    plt.plot(testPredictPlot)\n",
    "\n",
    "\n",
    "    x_input = test_data[X_test.shape[0]:].reshape(1,-1)\n",
    "    temp_input = list(x_input)\n",
    "    temp_input = temp_input[0].tolist()\n",
    "\n",
    "    # demonstrate prediction for next no of defined days\n",
    "    from numpy import array\n",
    "\n",
    "    lst_output = []\n",
    "    n_steps = 100\n",
    "    i = 0\n",
    "    no_of_days = 30\n",
    "\n",
    "    while(i < no_of_days):\n",
    "\n",
    "        if(len(temp_input)>100):\n",
    "            x_input = np.array(temp_input[1:])\n",
    "            x_input = x_input.reshape(1,-1)\n",
    "            x_input = x_input.reshape((1, n_steps, 1))\n",
    "            yhat = model_gru.predict(x_input, verbose=0)\n",
    "            temp_input.extend(yhat[0].tolist())\n",
    "            temp_input=temp_input[1:]\n",
    "            lst_output.extend(yhat.tolist())\n",
    "            i=i+1\n",
    "\n",
    "        else:\n",
    "            x_input = x_input.reshape((1, n_steps,1))\n",
    "            yhat = model_gru.predict(x_input, verbose=0)\n",
    "            temp_input.extend(yhat[0].tolist())\n",
    "            lst_output.extend(yhat.tolist())\n",
    "            i=i+1\n",
    "\n",
    "    final_out = scaler.inverse_transform(lst_output)\n",
    "    d = {'Output' : list(final_out)}\n",
    "    final_df = pd.DataFrame(d) \n",
    "    \n",
    "    import os \n",
    "    if os.path.isdir(company):\n",
    "        final_df.to_csv(company + '/' + company + '_gru.csv')\n",
    "        plt.savefig(company + '/' + company + '_gru.jpg')\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        os.mkdir(company)\n",
    "        final_df.to_csv(company + '/' + company + '_gru.csv')\n",
    "        plt.savefig(company + '/' + company + '_gru.jpg')\n",
    "        plt.show()\n",
    "\n",
    "    \n",
    "    print(\"--------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUTO-ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pmdarima.arima import auto_arima\n",
    "\n",
    "li_companies = ['TCS', 'HUL', 'INFY', 'SAIL', 'MRF', 'SRF', 'PVR.NS', 'IDBI.NS', 'RITES.NS']\n",
    "\n",
    "for company in li_companies:\n",
    "    \n",
    "    print(\"Comapny : \" + company)\n",
    "\n",
    "    import yfinance as yf\n",
    "    import numpy as np\n",
    "    import pandas as pd\n",
    "    data = yf.download(company, start=\"2015-01-01\")\n",
    "    df = data.dropna()\n",
    "\n",
    "    train = df[:int(df.shape[0]*0.75)]\n",
    "    valid = df[int(df.shape[0]*0.75):]\n",
    "\n",
    "    training = train['Close']\n",
    "    validation = valid['Close']\n",
    "\n",
    "    model = auto_arima(training, trace=True, error_action='ignore', suppress_warnings=True)\n",
    "    model.fit(training)\n",
    "\n",
    "    forecast = model.predict(n_periods=len(valid))\n",
    "    forecast = pd.DataFrame(forecast,index = valid.index,columns=['Prediction'])\n",
    "\n",
    "    rms=np.sqrt(np.mean(np.power((np.array(valid['Close'])-np.array(forecast['Prediction'])),2)))\n",
    "    print(\"rms : \", rms)\n",
    "\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.plot(train['Close'])\n",
    "    plt.plot(valid['Close'])\n",
    "    plt.plot(forecast['Prediction'])\n",
    "\n",
    "    import os \n",
    "    if os.path.isdir(company):\n",
    "        forecast.to_csv(company + '/' + company + '_arima.csv')\n",
    "        plt.savefig(company + '/' + company + '_arima.jpg')\n",
    "        plt.show()\n",
    "    \n",
    "    else:\n",
    "        os.mkdir(company)\n",
    "        forecast.to_csv(company + '/' + company + '_arima.csv')\n",
    "        plt.savefig(company + '/' + company + '_arima.jpg')\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"----------------------------------------------------------------------------------\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
